{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Tokenization Exercise\n",
    "\n",
    "This exercise explores the challenges of splitting text into sentences and words when dealing with complex real-world text containing dates, amounts, URLs, emails, acronyms, and multi-word expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Dr. John Smith, Ph.D., earned $1,250.50 on Jan. 15, 2024, for his work at A.I. Corp. You can reach him at j.smith@ai-corp.co.uk or visit https://www.ai-corp.co.uk/team/dr-smith for more info. The U.S.A.-based company reported a 23.5% increase in Q3 revenue, totaling €2.5M.\n"
     ]
    }
   ],
   "source": [
    "# Sample text with challenging elements\n",
    "text = \"\"\"Dr. John Smith, Ph.D., earned $1,250.50 on Jan. 15, 2024, for his work at A.I. Corp. You can reach him at j.smith@ai-corp.co.uk or visit https://www.ai-corp.co.uk/team/dr-smith for more info. The U.S.A.-based company reported a 23.5% increase in Q3 revenue, totaling €2.5M.\"\"\"\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "John Smith, Ph.D., earned $1,250.50 on Jan.\n",
      "15, 2024, for his work at A.I.\n",
      "Corp.\n",
      "You can reach him at j.smith@ai-corp.co.uk or visit https://www.ai-corp.co.uk/team/dr-smith for more info.\n",
      "The U.S.A.-based company reported a 23.5% increase in Q3 revenue, totaling €2.5M.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "for s in sentences:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dr.', 'John', 'Smith,', 'Ph.D.,', 'earned', '$1,250.50', 'on', 'Jan.', '15,', '2024,', 'for', 'his', 'work', 'at', 'A.I.', 'Corp.', 'You', 'can', 'reach', 'him', 'at', 'j.smith@ai-corp.co.uk', 'or', 'visit', 'https://www.ai-corp.co.uk/team/dr-smith', 'for', 'more', 'info.', 'The', 'U.S.A.-based', 'company', 'reported', 'a', '23.5%', 'increase', 'in', 'Q3', 'revenue,', 'totaling', '€2.5M.']\n"
     ]
    }
   ],
   "source": [
    "words = text.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. John Smith, Ph.D., earned $1,250.50 on Jan. 15, 2024, for his work at A.I. Corp.',\n",
       " 'You can reach him at j.smith@ai-corp.co.uk or visit https://www.ai-corp.co.uk/team/dr-smith for more info.',\n",
       " 'The U.S.A.-based company reported a 23.5% increase in Q3 revenue, totaling €2.5M.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentences\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "sentences = []\n",
    "for s in doc.sents:\n",
    "    sentences.append(s.text)\n",
    "\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.',\n",
       " 'John',\n",
       " 'Smith',\n",
       " ',',\n",
       " 'Ph.D.',\n",
       " ',',\n",
       " 'earned',\n",
       " '$',\n",
       " '1,250.50',\n",
       " 'on',\n",
       " 'Jan.',\n",
       " '15',\n",
       " ',',\n",
       " '2024',\n",
       " ',',\n",
       " 'for',\n",
       " 'his',\n",
       " 'work',\n",
       " 'at',\n",
       " 'A.I.',\n",
       " 'Corp.',\n",
       " 'You',\n",
       " 'can',\n",
       " 'reach',\n",
       " 'him',\n",
       " 'at',\n",
       " 'j.smith@ai-corp.co.uk',\n",
       " 'or',\n",
       " 'visit',\n",
       " 'https://www.ai-corp.co.uk/team/dr-smith',\n",
       " 'for',\n",
       " 'more',\n",
       " 'info',\n",
       " '.',\n",
       " 'The',\n",
       " 'U.S.A.-based',\n",
       " 'company',\n",
       " 'reported',\n",
       " 'a',\n",
       " '23.5',\n",
       " '%',\n",
       " 'increase',\n",
       " 'in',\n",
       " 'Q3',\n",
       " 'revenue',\n",
       " ',',\n",
       " 'totaling',\n",
       " '€',\n",
       " '2.5M.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens or words\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "tokens = []\n",
    "for token in doc:\n",
    "    tokens.append(token.text)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Tokenization Exercise\n",
    "\n",
    "This exercise explores the challenges of splitting words in large corpuses and find the most common words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('for', 2),\n",
       " ('at', 2),\n",
       " ('john', 1),\n",
       " ('smith', 1),\n",
       " ('earned', 1),\n",
       " ('on', 1),\n",
       " ('his', 1),\n",
       " ('work', 1),\n",
       " ('you', 1),\n",
       " ('can', 1),\n",
       " ('reach', 1),\n",
       " ('him', 1),\n",
       " ('or', 1),\n",
       " ('visit', 1),\n",
       " ('more', 1),\n",
       " ('info', 1),\n",
       " ('the', 1),\n",
       " ('company', 1),\n",
       " ('reported', 1),\n",
       " ('a', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"]) # Is the Name Entity  (not neccesary)\n",
    "tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.is_alpha:\n",
    "        word = token.text.lower() # lowercase letters\n",
    "        tokens.append(word) # Add to the list\n",
    "\n",
    "counts = Counter(tokens)\n",
    "count = counts.most_common(20)\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Challenge\n",
    "\n",
    "Given a file `shakes.txt` in the book folder. Find the words that are more common in Shakespeare's book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 27843),\n",
       " ('and', 26845),\n",
       " ('i', 20717),\n",
       " ('to', 19773),\n",
       " ('of', 18299),\n",
       " ('a', 14798),\n",
       " ('you', 13732),\n",
       " ('my', 12489),\n",
       " ('that', 11160),\n",
       " ('in', 11067),\n",
       " ('is', 9626),\n",
       " ('not', 8760),\n",
       " ('for', 8281),\n",
       " ('with', 8053),\n",
       " ('me', 7776),\n",
       " ('it', 7717),\n",
       " ('be', 7117),\n",
       " ('this', 6898),\n",
       " ('your', 6891),\n",
       " ('his', 6859)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "file = open(\"shakes.txt\")\n",
    "text = file.read()\n",
    "\n",
    "text = text.lower()  # lowercase \n",
    "# Extract words as king's\n",
    "pattern = r\"[a-z]+(?:'[a-z]+)?\"\n",
    "tokens = re.findall(pattern, text)\n",
    "\n",
    "# Count frecuency of words\n",
    "counts = Counter(tokens)\n",
    "count = counts.most_common(20)\n",
    "\n",
    "# results\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
